<h1 align="center">ğŸ¤– Smart Robotic Arm with Vision Tracking</h1>

<p align="center">
  <img src="https://img.shields.io/badge/C++-17-blue?logo=cplusplus&logoColor=white" />
  <img src="https://img.shields.io/badge/Python-3.10+-green?logo=python&logoColor=white" />
  <img src="https://img.shields.io/badge/YOLOv8-Ultralytics-orange?logo=yolo&logoColor=white" />
  <img src="https://img.shields.io/badge/OpenCV-4.5+-brightgreen?logo=opencv&logoColor=white" />
  <img src="https://img.shields.io/badge/Raspberry%20Pi-5-red?logo=raspberrypi&logoColor=white" />
  <img src="https://img.shields.io/badge/MQTT-WebSocket-purple?logo=mqtt&logoColor=white" />
  <a href="LICENSE">
    <img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License: MIT" />
  </a>
</p>

<p align="center">
  <img src="/placeholder.svg?height=400&width=700" />
</p>

<p align="center">
  <em>Comprehensive robotic arm system with real-time computer vision, dual control modes, and web dashboard for Raspberry Pi 5</em>
</p>

---

## ğŸŒŸ Features

- **ğŸ¯ Vision Tracking**: Real-time object detection using YOLOv8/OpenCV with automatic grabbing
- **ğŸ® Dual Control Modes**: Seamless switching between automatic vision-based and manual web control
- **ğŸ“Š Web Dashboard**: Real-time monitoring interface with dark/light themes and mobile support
- **ğŸ“ˆ Data Analytics**: CSV logging with Jupyter notebook analysis and performance insights
- **ğŸ”„ MQTT Communication**: Wireless control and status updates with WebSocket support
- **âš¡ Hybrid Architecture**: C++ for real-time hardware control, Python for AI processing
- **ğŸ›¡ï¸ Safety Features**: Emergency stop, position limits, and comprehensive error handling

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    A[Camera Input] --> B[YOLOv8 Detection]
    B --> C[Python Backend]
    C --> D[MQTT Broker]
    D --> E[C++ Hardware Controller]
    E --> F[Servo Motors]
    E --> G[Ultrasonic Sensor]
    C --> H[Web Dashboard]
    H --> I[Real-time Control]
    C --> J[Data Logger]
    J --> K[CSV Analytics]
```

## ğŸ“ Project Structure

```
smart-robotic-arm/
â”œâ”€â”€ ğŸ“‚ src/                     # C++ hardware control
â”‚   â”œâ”€â”€ main.cpp               # Main control loop & MQTT
â”‚   â”œâ”€â”€ servo_control.cpp      # 5-axis servo control
â”‚   â”œâ”€â”€ sensor_ultrasonic.cpp  # Distance measurement
â”‚   â””â”€â”€ driver_motor.cpp       # Motor driver interface
â”œâ”€â”€ ğŸ“‚ include/                # C++ headers & config
â”‚   â””â”€â”€ config.h              # GPIO pins & parameters
â”œâ”€â”€ ğŸ“‚ Backend python/         # Python AI & web backend
â”‚   â”œâ”€â”€ main.py               # Flask server & WebSocket
â”‚   â”œâ”€â”€ vision_tracking.py    # YOLOv8 object detection
â”‚   â”œâ”€â”€ data_logger.py        # CSV logging & analytics
â”‚   â”œâ”€â”€ analysis.ipynb        # Jupyter data analysis
â”‚   â””â”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ ğŸ“‚ dashboard/              # Web interface
â”‚   â”œâ”€â”€ index.html            # Main dashboard UI
â”‚   â”œâ”€â”€ page.js               # Control logic & charts
â”‚   â”œâ”€â”€ style.css             # Modern responsive design
â”‚   â””â”€â”€ assets/               # Icons & images
â”œâ”€â”€ ğŸ“‚ data/                   # Datasets & logs
â”‚   â”œâ”€â”€ dataset.csv           # Operation history
â”‚   â””â”€â”€ images/               # Captured frames
â”œâ”€â”€ ğŸ“‚ docs/                   # Documentation
â”‚   â”œâ”€â”€ API.md                # REST & WebSocket API
â”‚   â”œâ”€â”€ HARDWARE.md           # Wiring & assembly
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md    # Common issues
â”‚   â””â”€â”€ README.zh-en.md       # English documentation
â”œâ”€â”€ ğŸ“‚ scripts/                # Utility scripts
â”‚   â”œâ”€â”€ health_check.sh       # System diagnostics
â”‚   â”œâ”€â”€ start_system.sh       # Launch all services
â”‚   â””â”€â”€ stop_system.sh        # Graceful shutdown
â”œâ”€â”€ ğŸ”§ CMakeLists.txt           # C++ build configuration
â”œâ”€â”€ ğŸš€ setup.sh                # Automated installation
â””â”€â”€ ğŸ“‹ CITATION.cff            # Academic citation
```

## ğŸš€ Quick Start

### 1. Clone Repository
```bash
git clone https://github.com/ficrammanifur/smart-robotic-arm.git
cd smart-robotic-arm
```

### 2. Automated Setup
```bash
# Make setup script executable
chmod +x setup.sh

# Run automated installation
./setup.sh

# Reboot system
sudo reboot
```

### 3. Hardware Assembly
```bash
# Check hardware guide
cat docs/HARDWARE.md

# Test connections
./scripts/health_check.sh
```

### 4. Launch System
```bash
# Start all services
./scripts/start_system.sh

# Access dashboard
# Open http://localhost:5000 in browser
```

### 5. Manual Installation (Advanced)
```bash
# System dependencies
sudo apt update && sudo apt install -y cmake build-essential wiringpi
sudo apt install -y python3-pip python3-venv libopencv-dev mosquitto

# Build C++ components
mkdir build && cd build
cmake .. && make -j4

# Python environment
cd "Backend python"
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt
```

## ğŸ“Š System Performance

| Component | Specification | Performance | Power |
|-----------|--------------|-------------|-------|
| Detection | YOLOv8n 640px | 85.3% mAP, 30 FPS | 2.1W |
| Servos | 5x SG90/MG996R | 180Â° range, 0.1s/60Â° | 1.5W each |
| Processing | Raspberry Pi 5 | Quad-core 2.4GHz | 5-8W |
| Total System | Real-time control | <100ms latency | ~15W |

## ğŸ› ï¸ Hardware Requirements

### Essential Components
- **ğŸ–¥ï¸ Raspberry Pi 5** (4GB+ RAM recommended)
- **ğŸ¦¾ 5x Servo Motors** (SG90 or MG996R for higher torque)
- **ğŸ“¡ Ultrasonic Sensor** (HC-SR04 for distance measurement)
- **âš™ï¸ Motor Driver** (L298N or compatible)
- **ğŸ“· Camera Module** (Pi Camera v3 or USB webcam)

### Power & Connectivity
- **ğŸ”Œ Power Supply**: 5V 4A for Pi + 6V 2A for servos
- **ğŸ”— Breadboard** or custom PCB for connections
- **ğŸ“± MicroSD Card** (32GB+ Class 10 for optimal performance)

## ğŸ® Control Modes

### ğŸ¤– Automatic Mode
- Real-time object detection and tracking
- Autonomous grabbing sequences
- Collision avoidance with ultrasonic sensor
- Performance logging and optimization

### ğŸ¯ Manual Mode
- Web dashboard servo control
- Keyboard shortcuts (â†‘â†“â†â†’, Space, Esc)
- Real-time position feedback
- Emergency stop functionality

## ğŸ“ˆ Configuration

### Hardware Setup (`include/config.h`)
```cpp
// GPIO Pin Assignments (BCM)
#define SERVO_BASE_PIN 18      // Base rotation
#define SERVO_SHOULDER_PIN 19  // Shoulder joint
#define SERVO_ELBOW_PIN 20     // Elbow joint
#define SERVO_WRIST_PIN 21     // Wrist rotation
#define SERVO_GRIPPER_PIN 22   // Gripper control

// Detection Parameters
#define DETECTION_CONFIDENCE 0.5
#define MAX_OBJECTS 10
```

### Vision Settings (`Backend python/main.py`)
```python
# Camera Configuration
CAMERA_WIDTH = 640
CAMERA_HEIGHT = 480
FPS_TARGET = 30

# YOLO Parameters
CONFIDENCE_THRESHOLD = 0.25
IOU_THRESHOLD = 0.45
```

## ğŸ”§ API Documentation

### REST Endpoints
- **GET** `/api/status` - System health and statistics
- **POST** `/api/control` - Send movement commands
- **GET** `/api/detections` - Current object detections
- **GET** `/api/logs` - Operation history

### WebSocket Events
- `status` - Real-time system updates
- `detections` - Object detection events
- `control` - Manual control commands
- `emergency` - Safety alerts

### MQTT Topics
- `smartarm/control` - Command input
- `smartarm/status` - Status broadcasts
- `smartarm/data` - Sensor readings

## ğŸ” Troubleshooting

### Common Issues

**ğŸš« Hardware Not Detected**
```bash
# Check GPIO permissions
sudo usermod -a -G gpio $USER
./scripts/health_check.sh
```

**ğŸ“· Camera Issues**
```bash
# Verify camera connection
vcgencmd get_camera
libcamera-hello --timeout 5000
```

**ğŸŒ Dashboard Not Loading**
```bash
# Check Python backend
cd "Backend python" && python main.py --debug
netstat -tulpn | grep :5000
```

**âš¡ Performance Issues**
- Use Class 10+ SD card
- Increase GPU memory: `gpu_mem=128`
- External servo power supply
- Optimize camera resolution

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Follow code style guidelines (Black for Python, clang-format for C++)
4. Add tests and documentation
5. Submit pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) for object detection framework
- [OpenCV](https://opencv.org/) for computer vision utilities
- [Raspberry Pi Foundation](https://www.raspberrypi.org/) for the amazing hardware platform
- [Chart.js](https://www.chartjs.org/) for dashboard data visualization
- [MQTT.js](https://github.com/mqttjs/MQTT.js) for real-time communication

---

<div align="center">
  <p>â­ Star this repository if you find it useful!</p>
  <p>ğŸ¤– Built with â¤ï¸ for the robotics community</p>
  <p><a href="#top">â¬† Back to Top</a></p>
</div>
